#!/bin/sh
# The following lines instruct Slurm to allocate one GPU.
#SBATCH -o ./%A.out
#SBATCH -e ./%A.err
#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH -c12
#SBATCH --mem=60G
#SBATCH --time=15:00:00

# Set-up the environment.
source ${HOME}/.bashrc

# GPU
export CUDA_HOME="/usr/local/cuda-10.2"
export PATH="${CUDA_HOME}/bin:${PATH}"
export LIBRARY_PATH="${CUDA_HOME}/lib64:${LIBRARY_PATH}"
export LD_LIBRARY_PATH="${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}"
export HYDRA_FULL_ERROR=1
export NCCL_IB_DISABLE=1
export WANDB_DISABLED=true

# activate env
source activate noise_dr
export TRANSFORMERS_CACHE=/cache_models
export HF_DATASETS_CACHE=/cache_data
export TA_CACHE_DIR=/cache_data

# echo run info
echo "SLURM_SUBMIT_DIR="$SLURM_SUBMIT_DIR
echo "SLURM_JOB_ID"=$SLURM_JOB_ID
echo "SLURM_JOB_NAME"=$SLURM_JOB_NAME

NAME="bert_40"
LOAD_MODEL_DIR="model_msmarco_${NAME}"
SAVE_EMBEDDING_DIR="msmarco_${NAME}_embs" 
SAVE_RANK_DIR="rank_${NAME}"
echo "LOAD_MODEL_DIR: ${LOAD_MODEL_DIR}"
echo "SAVE_EMBEDDING_DIR: ${SAVE_EMBEDDING_DIR}"
echo "SAVE_RANK_DIR: ${SAVE_RANK_DIR}"

#mkdir $SAVE_EMBEDDING_DIR
mkdir $SAVE_RANK_DIR


# retrieve query dl-typo
python -m tevatron_dst.faiss_retriever \
  --query_reps ${SAVE_EMBEDDING_DIR}/query_dltypo_typo_emb.pkl \
  --passage_reps ${SAVE_EMBEDDING_DIR}/'corpus_emb.*.pkl' \
  --depth 1000 \
  --batch_size -1 \
  --save_text \
  --save_ranking_to ${SAVE_RANK_DIR}/dltypo_typo_rank.txt

python -m tevatron_dst.faiss_retriever \
  --query_reps ${SAVE_EMBEDDING_DIR}/query_dltypo_emb.pkl \
  --passage_reps ${SAVE_EMBEDDING_DIR}/'corpus_emb.*.pkl' \
  --depth 1000 \
  --batch_size -1 \
  --save_text \
  --save_ranking_to ${SAVE_RANK_DIR}/dltypo_rank.txt

python -m tevatron_dst.utils.format.convert_result_to_trec \
  --input ${SAVE_RANK_DIR}/dltypo_typo_rank.txt \
  --output ${SAVE_RANK_DIR}/dltypo_typo_rank.txt.trec

python -m tevatron_dst.utils.format.convert_result_to_trec \
  --input ${SAVE_RANK_DIR}/dltypo_rank.txt \
  --output ${SAVE_RANK_DIR}/dltypo_rank.txt.trec

# retrieve query msmarco dev
python -m tevatron_dst.faiss_retriever \
  --query_reps ${SAVE_EMBEDDING_DIR}/query_msmarco_emb.pkl \
  --passage_reps ${SAVE_EMBEDDING_DIR}/'corpus_emb.*.pkl' \
  --depth 1000 \
  --batch_size -1 \
  --save_text \
  --save_ranking_to ${SAVE_RANK_DIR}/msmarco_rank.txt

# retrieve query msmarco-typo dev
for s in $(seq 1 10)
do
python -m tevatron_dst.faiss_retriever \
  --query_reps ${SAVE_EMBEDDING_DIR}/query_msmarco_typo${s}_emb.pkl \
  --passage_reps ${SAVE_EMBEDDING_DIR}/'corpus_emb.*.pkl' \
  --depth 1000 \
  --batch_size -1 \
  --save_text \
  --save_ranking_to ${SAVE_RANK_DIR}/msmarco_typo${s}_rank.txt
done

